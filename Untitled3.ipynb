{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38f6b090e29d41449b26af0530e0f6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d61f7e19e084d83bf86cdfdcb8ff1fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_695ed9dff29141bf9ed5378cedcc254d",
              "IPY_MODEL_c762b0e17dde45ebb76da20f42a01ad3"
            ]
          }
        },
        "1d61f7e19e084d83bf86cdfdcb8ff1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "695ed9dff29141bf9ed5378cedcc254d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_afbec5e83fc04100b91df98f89652cc1",
            "_dom_classes": [],
            "description": "Epoch  1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1467,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1467,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3f09117903944a6b4cf464074cc00d2"
          }
        },
        "c762b0e17dde45ebb76da20f42a01ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_428fa7a897ff4188a7328bc9e4d5e40f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1467/1467 [06:56&lt;00:00,  3.52it/s, Loss 3.4034]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd6f8594676c467ca82f233eff7587f9"
          }
        },
        "afbec5e83fc04100b91df98f89652cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3f09117903944a6b4cf464074cc00d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "428fa7a897ff4188a7328bc9e4d5e40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd6f8594676c467ca82f233eff7587f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunhyeongil/docs-l10n/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVXfGicoYBuu",
        "outputId": "1bdff840-21d6-4a17-c83a-6479fe274b1b"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: colorama, beautifulsoup4, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFf3sjBVYEE4",
        "outputId": "8df70c77-2dc7-4bad-83e5-e7062ac8fa75"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBK6GUN5YGH3",
        "outputId": "6c5dc886-3b41-4146-f646-45d5d034f51e"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRX350-JYNYK",
        "outputId": "6023abf3-7cb3-46cb-fb2f-4f36d4c4262f"
      },
      "source": [
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-06-24 05:18:22--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22c2:513, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=3r8R4XVukktjrYpDwlKt2nnvRAw%3D&Expires=1624513353&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-24 05:18:23--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=3r8R4XVukktjrYpDwlKt2nnvRAw%3D&Expires=1624513353&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.10.171\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.10.171|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.54MB/s    in 0.4s    \n",
            "\n",
            "2021-06-24 05:18:23 (3.54 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-06-24 05:19:39--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=rW1d2ILkGcREve4UerzuuNh2UyE%3D&Expires=1624513421&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-24 05:19:40--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=rW1d2ILkGcREve4UerzuuNh2UyE%3D&Expires=1624513421&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.88.76\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.88.76|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  31.1MB/s    in 1.5s    \n",
            "\n",
            "2021-06-24 05:19:42 (31.1 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTMV05ByYOkZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sizxLTLDYRsE",
        "outputId": "2bd99e5c-3b3d-48c6-c2cb-a92c003cb2a9"
      },
      "source": [
        "!sudo apt -qq -y install fonts-nanum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 161068 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eykNBEPYTE1"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTTaaLAfYUhI"
      },
      "source": [
        "path_to_file_1 = '/content/drive/MyDrive/Colab Notebooks/dataset/korean-english-park.train.ko'\n",
        "path_to_file_2 = '/content/drive/MyDrive/Colab Notebooks/dataset/korean-english-park.train.en'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "texViSdzYV1h",
        "outputId": "88c9e107-02e0-4aac-9d8b-ec965c6530cc"
      },
      "source": [
        "with open(path_to_file_1, \"r\") as f:\n",
        "  train_raw = f.read().splitlines()\n",
        "\n",
        "print(\"Train Data Size :\", len(train_raw))\n",
        "print(\"Train_raw :\", train_raw[0:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Size : 94123\n",
            "Train_raw : ['개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"', '모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다.', '그러나 이것은 또한 책상도 필요로 하지 않는다.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2N_16jOYWzg",
        "outputId": "e71e0c31-492d-4c12-d777-9666d69e73a3"
      },
      "source": [
        "with open(path_to_file_2, \"r\") as f:\n",
        "  target_raw = f.read().splitlines()\n",
        "print(\"Target Data Size :\", len(target_raw))\n",
        "print(\"Target raw :\", target_raw[0:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Data Size : 94123\n",
            "Target raw : ['Much of personal computing is about \"can you top this?\"', 'so a mention a few weeks ago about a rechargeable wireless optical mouse brought in another rechargeable, wireless mouse.', \"Like all optical mice, But it also doesn't need a desk.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5JF1WYRYYCi",
        "outputId": "9956a453-8aad-45f1-92e4-9ae85f5c13a8"
      },
      "source": [
        "cleaned_corpus = set(zip(train_raw, target_raw))\n",
        "len(cleaned_corpus)\n",
        "q, r = len(set(train_raw)), len(set(target_raw))\n",
        "print(q, r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77591 75598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM55Oqp0YZI9",
        "outputId": "169a0d3a-e14a-40af-cbfb-1ce198632c65"
      },
      "source": [
        "train_dic = {}\n",
        "for i, j in enumerate(train_raw):\n",
        "  train_dic[i] =j\n",
        "target_dic = {}\n",
        "for i, j in enumerate(target_raw):\n",
        "  target_dic[i] = j\n",
        "\n",
        "target_unique_dic = {}\n",
        "for i, j in target_dic.items():\n",
        "  if j not in target_unique_dic.values():\n",
        "    target_unique_dic[i] = j\n",
        "\n",
        "train_unique_dic = {}\n",
        "for i, j in train_dic.items():\n",
        "  if i in target_unique_dic.keys():\n",
        "    train_unique_dic[i] = j\n",
        "\n",
        "print(len(train_unique_dic), len(target_unique_dic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75598 75598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MeguODVYamr"
      },
      "source": [
        "cleaned_eng_corpus = {}\n",
        "cleaned_kor_corpus = {}\n",
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKYCDDjzYb7z"
      },
      "source": [
        "def preprocess_sentence(train_unique_dic, target_unique_dic):\n",
        "    \n",
        "    for idx, sentence in target_unique_dic.items():\n",
        "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "        sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "        sentence = re.sub(r\"[^a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
        "        sentence = sentence.strip()\n",
        "        sentence_list = sentence.split()\n",
        "        if len(sentence_list) <= 48:\n",
        "            sentence = '<start> ' + sentence\n",
        "            sentence += ' <end>'\n",
        "            sentence = sentence.split()\n",
        "            cleaned_eng_corpus[idx] = sentence\n",
        "    \n",
        "    for idx, sentence in train_unique_dic.items():\n",
        "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "        sentence = re.sub(r'[\" \"]+', \" \", sentence)   \n",
        "        sentence = re.sub(r\"[^ㄱ-ㅎ가-힣0-9.,?!]+\", \" \", sentence)\n",
        "        result = mecab.morphs(sentence)\n",
        "        if len(result) <= 50:\n",
        "            cleaned_kor_corpus[idx] = result\n",
        "    \n",
        "    return cleaned_eng_corpus, cleaned_kor_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykiYQ9HGYdHx"
      },
      "source": [
        "cleaned_eng_corpus, cleaned_kor_corpus = preprocess_sentence(train_unique_dic, target_unique_dic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmB1Un1CYeRc",
        "outputId": "a8caf052-c379-4599-99bd-453cb7459215"
      },
      "source": [
        "print(cleaned_eng_corpus[100],cleaned_kor_corpus[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<start>', 'Gates', ',', 'who', 'opened', 'the', '23rd', 'annual', 'Comdex', 'trade', 'show', ',', 'said', 'there', 'was', 'a', 'negative', 'perception', 'of', 'high', 'tech', 'following', 'the', 'collapse', 'of', 'the', 'tech', 'bubble', 'about', 'two', 'years', 'ago', '.', '<end>'] ['제', '23', '차', '연례', '컴덱스', '박람회', '의', '개회사', '를', '한', '케이츠', '는', '2', '년', '여전', '기술', '산업', '의', '거품', '이', '붕괴', '된', '이후', '에', '첨단', '기술', '에', '대해', '부정', '적', '인', '인식', '이', '있', '다고', '말', '했', '다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JtfCFqDYfR1",
        "outputId": "c9e6374a-489a-4eac-fa87-64135caf8a9e"
      },
      "source": [
        "print(len(cleaned_eng_corpus), len(cleaned_kor_corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73415 71573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TPAA3WDYgZ8",
        "outputId": "fb1704e3-9d70-4ff2-a15b-aad069317077"
      },
      "source": [
        "set_temp1 = set(cleaned_eng_corpus.keys())\n",
        "set_temp2 = set(cleaned_kor_corpus.keys())\n",
        "set_temp3 = set_temp2.intersection(set_temp1)\n",
        "len(set_temp3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPS7Wbq0YhPx",
        "outputId": "8b17a398-73da-4589-b2ac-06bde8c31a30"
      },
      "source": [
        "train_list = []\n",
        "target_list = []\n",
        "\n",
        "for i, j in cleaned_eng_corpus.items():\n",
        "    if i in set_temp3:\n",
        "        target_list.append(j)\n",
        "        \n",
        "for i, j in cleaned_kor_corpus.items():\n",
        "    if i in set_temp3:\n",
        "        train_list.append(j)\n",
        "print(len(train_list), len(target_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70406 70406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpCNab8zYiPt"
      },
      "source": [
        "del q\n",
        "del r\n",
        "del train_dic\n",
        "del target_dic\n",
        "del train_unique_dic\n",
        "del target_unique_dic\n",
        "del cleaned_eng_corpus\n",
        "del cleaned_kor_corpus\n",
        "del set_temp1\n",
        "del set_temp2\n",
        "del set_temp3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEf4XsjPYjhm"
      },
      "source": [
        "maxlen = 50\n",
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', num_words=20000)\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen = maxlen)\n",
        "\n",
        "    return tensor, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhxgo9LrYkzB",
        "outputId": "4a92ebf0-7965-480e-e193-e08b85416f30"
      },
      "source": [
        "enc_tensor, enc_vocab = tokenize(train_list)\n",
        "dec_tensor, dec_vocab = tokenize(target_list)\n",
        "\n",
        "print(\"Korean vocab size: \", len(enc_vocab.index_word))\n",
        "print(\"English vocab size :\", len(dec_vocab.index_word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Korean vocab size:  41750\n",
            "English vocab size : 44129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUDiWLfVYl-L",
        "outputId": "e7fac3c5-f9d7-4602-d6e6-6b410e48b5c7"
      },
      "source": [
        "print(len(enc_tensor[12400]), len(dec_tensor[12400]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-SAaoNKYnAy"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.w_dec = tf.keras.layers.Dense(units)\n",
        "    self.w_enc = tf.keras.layers.Dense(units)\n",
        "    self.w_com = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, h_enc, h_dec):\n",
        "    # h_enc shape : [batch x length x units]\n",
        "    # h_enc shape : [batch x units]\n",
        "\n",
        "    h_enc = self.w_enc(h_enc)\n",
        "    h_dec = tf.expand_dims(h_dec, 1)\n",
        "    h_dec = self.w_dec(h_dec)\n",
        "\n",
        "    score = self.w_com(tf.nn.tanh(h_dec+h_enc))\n",
        "\n",
        "    attn = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    context_vec = attn * h_enc\n",
        "    context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "\n",
        "    return context_vec, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAGdOm3yYoL2"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(enc_units, return_sequences=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    out = self.embedding(x)\n",
        "    out = self.gru(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhT3K1hUYpli"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state = True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, h_dec, enc_out):\n",
        "    context_vec, attn = self.attention(enc_out, h_dec)\n",
        "\n",
        "    out = self.embedding(x)\n",
        "    out = tf.concat([tf.expand_dims(context_vec, 1), out], axis = -1)\n",
        "\n",
        "    out, h_dec = self.gru(out)\n",
        "    out = tf.reshape(out, (-1, out.shape[2]))\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out, h_dec, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am0iM6ULYqgT",
        "outputId": "bc9d4cc8-ba37-4f2e-c23b-32fa671f9e22"
      },
      "source": [
        "batch_size = 48\n",
        "src_vocab_size = len(enc_vocab.index_word)+1\n",
        "tgt_vocab_size = len(dec_vocab.index_word)+1\n",
        "\n",
        "units = 128\n",
        "embedding_dim = 128\n",
        "\n",
        "encoder = Encoder(src_vocab_size, embedding_dim, units)\n",
        "decoder = Decoder(tgt_vocab_size, embedding_dim, units)\n",
        "\n",
        "sequence_len = 50\n",
        "\n",
        "sample_enc = tf.random.uniform((batch_size, sequence_len)) \n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print('Encoder Output :', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((batch_size, units))\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((batch_size, 1)),\n",
        "                                     sample_state, sample_output)\n",
        "\n",
        "print('Decoder Output:', sample_logits.shape)\n",
        "print('Decoder Hidden state:', h_dec.shape)\n",
        "print('Attention:', attn.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder Output : (48, 50, 128)\n",
            "Decoder Output: (48, 44130)\n",
            "Decoder Hidden state: (48, 128)\n",
            "Attention: (48, 50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3dddijjYrak"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real,0))\n",
        "  loss = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nRkk6L7YsY3"
      },
      "source": [
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
        "  bsz = src.shape[0]\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_out = encoder(src)\n",
        "    h_dec = enc_out[:, -1]\n",
        "\n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']]*bsz ,1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "      pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "      loss += loss_function(tgt[:, t], pred)\n",
        "      dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss/int(tgt.shape[1]))\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcBlzEpjYtTM",
        "outputId": "8804cd06-2544-4f90-9510-0ef704ccd219"
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "38f6b090e29d41449b26af0530e0f6af",
            "1d61f7e19e084d83bf86cdfdcb8ff1fe",
            "695ed9dff29141bf9ed5378cedcc254d",
            "c762b0e17dde45ebb76da20f42a01ad3",
            "afbec5e83fc04100b91df98f89652cc1",
            "e3f09117903944a6b4cf464074cc00d2",
            "428fa7a897ff4188a7328bc9e4d5e40f",
            "fd6f8594676c467ca82f233eff7587f9"
          ]
        },
        "id": "szG07rKVYvWZ",
        "outputId": "e88d7736-9e5a-4942-a6ab-26f44018deee"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  idx_list = list(range(0, enc_tensor.shape[0], batch_size))\n",
        "  random.shuffle(idx_list)\n",
        "  t = tqdm(idx_list)\n",
        "\n",
        "  for (batch, idx) in enumerate(t):\n",
        "    batch_loss = train_step(enc_tensor[idx:idx+batch_size],\n",
        "                            dec_tensor[idx:idx+batch_size],\n",
        "                            encoder,\n",
        "                            decoder,\n",
        "                            optimizer,\n",
        "                            dec_vocab)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "    t.set_postfix_str('Loss %.4f'% (total_loss.numpy() / (batch+1)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38f6b090e29d41449b26af0530e0f6af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1467.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpQEJ4nTY1n6"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \",sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  sentence = re.sub(r\"[^ㄱ-ㅎ가-힣0-9.,?!]+\", \" \", sentence)\n",
        "  result = mecab.morphs(sentence)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewfsWtDbhcHq"
      },
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "  attention = np.zeros((dec_tensor.shape[-1], enc_tensor.shape[-1]))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  inputs = enc_vocab.texts_to_sequences([sentence])\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                         maxlen=enc_tensor.shape[-1],\n",
        "                                                         padding='post')\n",
        "  result = ''\n",
        "  enc_out = encoder(inputs)\n",
        "\n",
        "  dec_hidden = enc_out[:, -1]\n",
        "  dec_input = tf.expand_dims([dec_vocab.word_index['<start>']],0)\n",
        "\n",
        "  for t in range(dec_tensor.shape[-1]):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = \\\n",
        "    tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "    result += dec_vocab.index_word[predicted_id] + ' '\n",
        "\n",
        "    if dec_vocab.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_weights\n",
        "    \n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  return result, sentence, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhG2FydgjDJg"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap = 'viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels(['']+sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels(['']+predicted_sentence, fontdict = fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-9R2dRmjqnl"
      },
      "source": [
        "def translate(sentence, encoder, decoder):\n",
        "  result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "  print('Input: %s '% (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention = attention[:len(result), :len(sentence)]\n",
        "  plot_attention(attention, sentence, result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2UZDwZVkFYJ"
      },
      "source": [
        "##  번역 품질 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kMKK35J0kAnW",
        "outputId": "d9ced876-cd28-45f9-c7e4-e75d906de163"
      },
      "source": [
        "translate(\"일곱 명의 사망자가 발생했다.\", encoder, decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: ['일곱', '명', '의', '사망자', '가', '발생', '했', '다', '.'] \n",
            "Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51068 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44273 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47749 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51032 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49324 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47581 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51088 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44032 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48156 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54664 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51068 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44273 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47749 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51032 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49324 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47581 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51088 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44032 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48156 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54664 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 143,
              "height": 593
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG4vMJy3kMQf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}